{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Seed:  999\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f62c98a8ef0>"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "#%matplotlib inline\n",
    "import argparse\n",
    "import os\n",
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.parallel\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.optim as optim\n",
    "import torch.utils.data\n",
    "import torchvision.datasets as dset\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.utils as vutils\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as animation\n",
    "from IPython.display import HTML\n",
    "from time import time\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "manualSeed = 999\n",
    "#manualSeed = random.randint(1, 10000) # use if you want new results\n",
    "print(\"Random Seed: \", manualSeed)\n",
    "random.seed(manualSeed)\n",
    "torch.manual_seed(manualSeed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import imageio\n",
    "from matplotlib import pyplot as plt\n",
    "fs = os.listdir('bam_dataset_download/downloaded/')\n",
    "print(len(fs))\n",
    "for f in list(fs)[:10]:\n",
    "    img = imageio.imread('bam_dataset_download/downloaded/' + f)\n",
    "    plt.imshow(img)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "original_ds = dset.ImageFolder(root='./data',\n",
    "                           transform=transforms.Compose([\n",
    "                               transforms.ToTensor(),\n",
    "                               transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "                           ]))\n",
    "# Create the dataloader\n",
    "original_dl = torch.utils.data.DataLoader(original_ds, batch_size=1,\n",
    "                                         shuffle=False, num_workers=4)\n",
    "\n",
    "\n",
    "\n",
    "image_size = 256\n",
    "dataset = dset.ImageFolder(root='./data',\n",
    "                           transform=transforms.Compose([\n",
    "                               #transforms.RandomApply([\n",
    "                               #    transforms.RandomAffine(0, translate=None, scale=(0.8, 1.2), shear=None)], p=0.1),\n",
    "                               transforms.Resize(image_size),\n",
    "                               transforms.RandomCrop(image_size),\n",
    "                               #transforms.RandomApply([\n",
    "                               #    transforms.RandomAffine(4, translate=None, scale=None, shear=5)], p=0.2),\n",
    "                               transforms.ColorJitter(brightness=0.15, contrast=0.15, saturation=0.15, hue=0.1),\n",
    "                               transforms.RandomHorizontalFlip(p=0.5),\n",
    "                               transforms.ToTensor(),\n",
    "                               transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "                           ]))\n",
    "# Create the dataloader\n",
    "dataloader = torch.utils.data.DataLoader(dataset, batch_size=1,\n",
    "                                         shuffle=False, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (bad) benchmark (keep in mind this does not include performance gains due to large batch sizes, using gpu,..)\n",
    "t0 = time()\n",
    "\n",
    "for i, data in enumerate(dataloader):\n",
    "    if i > 300:\n",
    "        break\n",
    "    \n",
    "print(time()-t0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "for i, a in enumerate(zip(dataloader, original_dl)):\n",
    "    if i % 25 == 7:\n",
    "        transformed_img, original_img = a\n",
    "        plt.imshow(((transformed_img[0][0].numpy()+1)/2).transpose((1, 2, 0)))\n",
    "        plt.show()\n",
    "        plt.imshow(((original_img[0][0].numpy()+1)/2).transpose((1, 2, 0)))\n",
    "        plt.show()\n",
    "        \n",
    "    if i > 25*18:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "image_size = 256\n",
    "dataset = dset.ImageFolder(root='./data',\n",
    "                           transform=transforms.Compose([\n",
    "                               transforms.Resize(image_size),\n",
    "                               transforms.RandomCrop(image_size),\n",
    "                               transforms.RandomHorizontalFlip(p=0.5),\n",
    "                               transforms.ToTensor(),\n",
    "                           ]))\n",
    "dl2 = torch.utils.data.DataLoader(dataset, batch_size=1,\n",
    "                                         shuffle=True, num_workers=1)\n",
    "\n",
    "sum_img = np.zeros((image_size, image_size, 3))\n",
    "k = 0\n",
    "\n",
    "\n",
    "for i, data in enumerate(dl2):\n",
    "    sum_img += data[0][0].numpy().transpose((1, 2, 0))\n",
    "    \n",
    "    #print(np.min(data[0][0].numpy().transpose((1, 2, 0))), np.max(data[0][0].numpy().transpose((1, 2, 0))))\n",
    "    k += 1\n",
    "    \n",
    "    if i > 200:\n",
    "        break\n",
    "        \n",
    "        \n",
    "plt.imshow(sum_img/k)\n",
    "print('min/max of overall mean image:', np.min(sum_img/k, axis=(0, 1)), np.max(sum_img/k, axis=(0, 1)))\n",
    "print('mean channel values:', np.mean(sum_img/k, axis=(0, 1)))\n",
    "print('std channel values (this seems to be incorrect?!):', np.std(sum_img/k, axis=(0, 1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import imageio\n",
    "import random\n",
    "from matplotlib import pyplot as plt\n",
    "fs = list(os.listdir('cropped_TRAIN/'))\n",
    "random.shuffle(fs)\n",
    "print(len(fs))\n",
    "for f in fs[:100]:\n",
    "    img = imageio.imread('cropped_TRAIN/' + f)\n",
    "    plt.imshow(img)\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
